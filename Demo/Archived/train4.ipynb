{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Introduction for the Trainer Class\n",
    "\n",
    "This demo provides a hands-on introduction to the Trainer class, which is designed to facilitate the training and evaluation of the Inception-based classifier for time series data. The demo will guide you through the process of training the model on multiple datasets, evaluating its performance, and consolidating the results.\n",
    "\n",
    "## How to Use the Demo:\n",
    "\n",
    "1. Setup:\n",
    "\n",
    "    Ensure that all the necessary dependencies and the Package module are accessible or available in the directory structure.\n",
    "    Create a directory named \"result\" to store the training and evaluation metrics.\n",
    "\n",
    "2. Training and Evaluation:\n",
    "\n",
    "    For each dataset in the datasets list, an instance of the Trainer class is created.\n",
    "    The train_and_evaluate() method is then called for each dataset, which trains the model and evaluates its performance on the test data.\n",
    "\n",
    "3. Consolidation of Results:\n",
    "\n",
    "- After training and evaluation are completed for all datasets, the concat_metrics_train function is called twice:\n",
    "\n",
    "    - First, to consolidate the training metrics across all datasets.\n",
    "\n",
    "    - Second, to consolidate the test metrics across all datasets.\n",
    "\n",
    "## What the Demo Does:\n",
    "\n",
    "- Training: For each dataset, the model is trained for a specified number of epochs. During training, the model's weights are updated using the Adam optimizer, and the learning rate is adjusted using a scheduler based on the test loss.\n",
    "\n",
    "- Evaluation: After training, the model's performance is evaluated on the test dataset. Metrics such as loss, accuracy, precision, recall, and F1 score are computed.\n",
    "\n",
    "- Logging and Checkpointing: The demo automatically handles checkpoints, saving model weights, and logging. For every 50 epochs, the model weights are saved, and the old weights are deleted to save storage space.\n",
    "\n",
    "- Result Consolidation: After training and evaluation for all datasets, the metrics are consolidated into two files:\n",
    "\n",
    "    - A file containing consolidated training metrics across all datasets.\n",
    "\n",
    "    - A file containing consolidated test metrics across all datasets.\n",
    "\n",
    "## Generated Files:\n",
    "\n",
    "- Model Weights: For each dataset, the final model weights are saved in a directory named after the dataset under the \"result\" directory.\n",
    "\n",
    "- Metrics: Two files, one for training metrics and one for test metrics, are generated in the \"result\" directory. These files consolidate the metrics across all datasets.\n",
    "\n",
    "- Logs: Logs related to training progress, evaluation results, and other relevant information are saved.\n",
    "\n",
    "To run the demo, simply execute the provided demo code. Ensure that the necessary datasets are available and that the system has the required computational resources, especially if GPU acceleration is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please ensure the location of this ipynb file are in \"demo\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd: /Project/Local_Project/InceptionTime/CorrelationV0.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "__file__ = %pwd\n",
    "sys.path.append(os.path.dirname(__file__))\n",
    "from __init__ import *\n",
    "print('pwd:', __file__)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_TRAIN_PARAMETER[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CODE.Train.inception_time.Classifier_INCEPTION"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DICT[DEFAULT_TRAIN_PARAMETER[\"model\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_DATASETs = UNIVARIATE_DATASET_NAMES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00194: reducing learning rate of group 0 to 5.0000e-04.\n",
      "Epoch 00245: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch 00331: reducing learning rate of group 0 to 1.2500e-04.\n",
      "Epoch 00452: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.4945927858352661,\n",
       " 'accuracy': 0.98,\n",
       " 'precision': 0.9818181818181818,\n",
       " 'recall': 0.9800000000000001,\n",
       " 'f1': 0.9799498746867169,\n",
       " 'duration': 101.11870861053467}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(dataset=part_DATASETs[0], epoch=1000)\n",
    "trainer.train_and_evaluate(to_device=True, override=True)\n",
    "trainer.train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODE.Attack.mix\n"
     ]
    }
   ],
   "source": [
    "keys = []\n",
    "for k in sys.modules.keys():\n",
    "    if \"CODE.Attack.mix\" in k:\n",
    "        print(k)\n",
    "        keys.append(k)\n",
    "for k in keys:\n",
    "    del sys.modules[k]\n",
    "\n",
    "from CODE.Attack.mix import Mix\n",
    "\n",
    "model_class = Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ASR': 0.69,\n",
      " 'Count_Fail': 31,\n",
      " 'Count_Success': 69,\n",
      " 'duration': 71.15822529792786,\n",
      " 'mean_failure_distance': 11.775487,\n",
      " 'mean_success_distance': 7.011273,\n",
      " 'overall_mean_distance': 8.488179}\n"
     ]
    }
   ],
   "source": [
    "attacker = model_class(\n",
    "    train_method_path=trainer.method_path,\n",
    "    dataset=part_DATASETs[0],\n",
    ")\n",
    "\n",
    "attacker.perturb_all(\n",
    "    to_device=True,\n",
    "    override=True,\n",
    ")\n",
    "pprint(attacker.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Stop here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStop here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: Stop here"
     ]
    }
   ],
   "source": [
    "raise Exception(\"Stop here\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
